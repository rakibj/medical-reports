{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8739d6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96551893",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"time\": {\n",
    "            \"transport\": \"stdio\",                 # âœ… required\n",
    "            \"command\": \"uvx\",                     # uvx will run the CLI from PyPI\n",
    "            \"args\": [\"mcp-server-time\", \"--local-timezone=Asia/Dhaka\"],\n",
    "            # Optional:\n",
    "            # \"env\": {\"PYTHONUNBUFFERED\": \"1\"},\n",
    "            # \"request_timeout\": 120,\n",
    "            # \"idle_timeout\": 300,\n",
    "        },\n",
    "        \"edgeone-pages-mcp-server\": {\n",
    "            \"transport\": \"stdio\",\n",
    "            \"command\": \"npx\",\n",
    "            \"args\": [\"edgeone-pages-mcp\"],\n",
    "            # If your npx command needs env, you can add:\n",
    "            # \"env\": {\"NODE_OPTIONS\": \"...\"}\n",
    "        },\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d4f2c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = await client.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45ba1bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='get_current_time', description='Get current time in a specific timezones', args_schema={'type': 'object', 'properties': {'timezone': {'type': 'string', 'description': \"IANA timezone name (e.g., 'America/New_York', 'Europe/London'). Use 'Asia/Dhaka' as local timezone if no timezone provided by the user.\"}}, 'required': ['timezone']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x75a9f3f0c400>),\n",
       " StructuredTool(name='convert_time', description='Convert time between timezones', args_schema={'type': 'object', 'properties': {'source_timezone': {'type': 'string', 'description': \"Source IANA timezone name (e.g., 'America/New_York', 'Europe/London'). Use 'Asia/Dhaka' as local timezone if no source timezone provided by the user.\"}, 'time': {'type': 'string', 'description': 'Time to convert in 24-hour format (HH:MM)'}, 'target_timezone': {'type': 'string', 'description': \"Target IANA timezone name (e.g., 'Asia/Tokyo', 'America/San_Francisco'). Use 'Asia/Dhaka' as local timezone if no target timezone provided by the user.\"}}, 'required': ['source_timezone', 'time', 'target_timezone']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x75a9f3f0e0c0>),\n",
       " StructuredTool(name='deploy_html', description='Deploy HTML content to EdgeOne Pages, return the public URL', args_schema={'type': 'object', 'properties': {'value': {'type': 'string', 'description': 'Provide the full HTML markup you wish to publish.\\nAfter deployment, the system will generate and return a public URL where your content can be accessed.'}}, 'required': ['value'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x75a9f3f0ea20>),\n",
       " StructuredTool(name='deploy_folder_or_zip', description='Deploy a built frontend directory (or zip file) to EdgeOne Pages. Returns: the deployment URL and project metadata.', args_schema={'type': 'object', 'properties': {'builtFolderPath': {'type': 'string', 'description': 'Provide the absolute path to the built frontend folder(or zip file) you wish to deploy.'}}, 'required': ['builtFolderPath'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x75a9f3f0e5c0>)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8cd0f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current time in Dhaka is 09:44 AM on September 6, 2025.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent = create_react_agent(\"gpt-4o-mini\", tools)\n",
    "response = await agent.ainvoke({'messages': [{'role': 'user', 'content': \"Whats the current time in Dhaka?\"}]})\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18c7b9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gradio_history_to_messages(history):\n",
    "    \"\"\"Convert Gradio history (tuples or dicts) into LangGraph MessagesState list.\"\"\"\n",
    "    messages = []\n",
    "    for turn in history:\n",
    "        # Tuple/list style: (user, assistant)\n",
    "        if isinstance(turn, (list, tuple)) and len(turn) == 2:\n",
    "            user_msg, assistant_msg = turn\n",
    "            if user_msg:\n",
    "                messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "            if assistant_msg:\n",
    "                messages.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
    "        # Dict style: {\"role\": \"...\", \"content\": \"...\"} (some Gradio configs/plugins)\n",
    "        elif isinstance(turn, dict) and \"role\" in turn and \"content\" in turn:\n",
    "            messages.append({\"role\": turn[\"role\"], \"content\": turn[\"content\"]})\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "745a36f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Work/Projects/Ubuntu_Home/projects/ownership-ai/.venv/lib/python3.12/site-packages/gradio/chat_interface.py:345: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "async def chat(user_message, history):\n",
    "    messages = _gradio_history_to_messages(history)\n",
    "    messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "    # Call your LangGraph agent\n",
    "    result = await agent.ainvoke({\"messages\": messages})\n",
    "\n",
    "    # Return only the assistant text; ChatInterface updates history itself\n",
    "    return result[\"messages\"][-1].content\n",
    "\n",
    "\n",
    "gr.ChatInterface(chat, title=\"LangGraph MCP Agent\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e47cf02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ownership-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
